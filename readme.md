# üìä Proyecto de An√°lisis de Sentimientos en Tweets

Este proyecto tiene como objetivo desarrollar un sistema de an√°lisis de sentimientos para tweets, clasific√°ndolos como positivos o negativos. Utilizando un conjunto de datos de 1.6 millones de tweets preprocesados, el proyecto implementa diversas t√©cnicas de procesamiento de lenguaje natural (NLP) y aprendizaje autom√°tico para lograr una clasificaci√≥n precisa.

## üéØ Problema de Negocio

El an√°lisis de sentimientos en redes sociales, particularmente en Twitter, tiene m√∫ltiples aplicaciones comerciales y de investigaci√≥n:
- Monitoreo de la percepci√≥n de marca
- An√°lisis de la recepci√≥n de productos o servicios
- Detecci√≥n de tendencias en la opini√≥n p√∫blica
- Seguimiento de la satisfacci√≥n del cliente

Este proyecto busca crear un modelo robusto que pueda identificar autom√°ticamente si un tweet expresa un sentimiento positivo o negativo.

## üìä Contenido del Repositorio

- `TwitterSentiment_ML_Models.ipynb`: Notebook principal que contiene el c√≥digo para la extracci√≥n de caracter√≠sticas y modelos de clasificaci√≥n de sentimientos en tweets
- `Visualizaciones/`: Carpeta que contiene im√°genes de visualizaci√≥n de datos
  - `distribucion_polaridad.JPG`: Visualizaci√≥n de la distribuci√≥n de polaridad en los tweets
  - `distribucion_sentimientos.JPG`: Visualizaci√≥n de la distribuci√≥n de sentimientos positivos, negativos y neutros
- Pr√≥ximamente: Notebooks adicionales para an√°lisis avanzados y experimentaci√≥n

## üîç Enfoque Metodol√≥gico

### Preprocesamiento de Datos
- Limpieza de texto (eliminaci√≥n de URLs, menciones, caracteres especiales)
- Normalizaci√≥n (conversi√≥n a min√∫sculas, manejo de emojis)
- Tokenizaci√≥n y eliminaci√≥n de stopwords

### Extracci√≥n de Caracter√≠sticas
El proyecto implementa diversas t√©cnicas para extraer caracter√≠sticas relevantes:
- Longitud del tweet
- Conteo de emojis
- Presencia de signos de exclamaci√≥n e interrogaci√≥n
- Caracter√≠sticas l√©xicas (palabras positivas/negativas)
- Vectorizaci√≥n de texto (Bag of Words, TF-IDF)
- An√°lisis de sentimiento basado en diccionarios (VADER, TextBlob)

### Modelado
El proyecto implementa tres modelos distintos para la clasificaci√≥n de sentimientos:
- **XGBoost** (sin caracter√≠sticas enriquecidas): Algoritmo de boosting optimizado para rendimiento
- **LightGBM** (sin caracter√≠sticas enriquecidas): Framework de gradient boosting eficiente y r√°pido
- **LightGBM** (con caracter√≠sticas enriquecidas): Versi√≥n mejorada con caracter√≠sticas adicionales

Cada modelo fue entrenado y optimizado utilizando:
- Validaci√≥n cruzada para evaluar el rendimiento
- Optimizaci√≥n de hiperpar√°metros para mejorar la precisi√≥n
- T√©cnicas de balanceo de clases para manejar posibles desbalances en los datos

## üìä Visualizaciones

A continuaci√≥n se muestran algunas visualizaciones clave del an√°lisis:

### Distribuci√≥n de Polaridad
![Distribuci√≥n de Polaridad](distribucion_polaridad.JPG)
*Distribuci√≥n de los valores de polaridad en el conjunto de datos, mostrando la frecuencia de diferentes niveles de sentimiento.*

### Distribuci√≥n de Sentimientos
![Distribuci√≥n de Sentimientos](distribucion_sentimientos.JPG)
*Comparaci√≥n de la frecuencia de tweets positivos, negativos y neutrales en el conjunto de datos.*

Estas visualizaciones ayudan a entender la distribuci√≥n de sentimientos en los datos y confirman el correcto funcionamiento de los modelos de clasificaci√≥n implementados.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python**: Lenguaje principal de programaci√≥n
- **Pandas**: Manipulaci√≥n y an√°lisis de datos
- **NLTK**: Procesamiento de lenguaje natural
- **scikit-learn**: Algoritmos de aprendizaje autom√°tico
- **VADER**: An√°lisis de sentimientos basado en reglas
- **TextBlob**: Procesamiento de texto y an√°lisis de sentimientos
- **Emoji**: Manejo y procesamiento de emojis

## üìà Resultados

### Rendimiento de los Modelos

| Modelo | Accuracy | Negativo (P/R/F1) | Positivo (P/R/F1) |
|--------|----------|-------------------|-------------------|
| XGBoost sin enriquecidas | 0.7819 | 0.80/0.75/0.77 | 0.77/0.81/0.79 |
| LightGBM sin enriquecidas | 0.7813 | 0.80/0.75/0.77 | 0.76/0.82/0.79 |
| LightGBM con enriquecidas | 0.7838 | 0.80/0.76/0.78 | 0.77/0.81/0.79 |

#### Principales Hallazgos:

- **LightGBM con caracter√≠sticas enriquecidas** logra el mejor rendimiento global (78.38%)
- Las caracter√≠sticas enriquecidas mejoran el recall de tweets negativos sin sacrificar significativamente la precisi√≥n
- Los tres modelos son robustos y consistentes, con un rendimiento cercano al 78%
- La base de TF-IDF proporciona buenos resultados por s√≠ sola, y las variables enriquecidas refinan los resultados

### Ejemplo de Predicci√≥n

```
Text Original: "Hello @leopoldo. Bootcam excelent!!!! Don't worry. All will be best always. No Change"
Text Limpio: "hello bootcam excelent dont worry all will be best always no change"

Resultados:
- XGBoost (sin caracter√≠sticas enriquecidas): Positivo
- LightGBM (sin caracter√≠sticas enriquecidas): Positivo
- LightGBM (con caracter√≠sticas enriquecidas): Positivo
```

Los tres modelos clasificaron correctamente este ejemplo como positivo, demostrando la robustez del sistema desarrollado.

## üîú Pr√≥ximos Pasos

- Ampliar el conjunto de datos de entrenamiento con tweets m√°s recientes
- Experimentar con arquitecturas avanzadas como BERT o GPT para comparar rendimiento
- Implementar una interfaz web para demostraciones interactivas
- Desarrollar una API para integraciones con otras aplicaciones
- A√±adir soporte para an√°lisis multiling√ºe
- Implementar an√°lisis de sentimientos con mayor granularidad (m√°s all√° de binario positivo/negativo)

## üîó Referencias

- Dataset: Sentiment140 (1.6 millones de tweets etiquetados)
- Documentaci√≥n de las bibliotecas utilizadas (NLTK, scikit-learn, etc.)
- Art√≠culos acad√©micos sobre an√°lisis de sentimientos en redes sociales

---

‚ö†Ô∏è **Nota**: Este proyecto se encuentra en desarrollo y se actualizar√° regularmente con nuevos avances y resultados.
